#%% Section 1: Importar bibliotecas e configurar caminhos
import os
import shutil
import torch
from torchvision import datasets, models, transforms
from torch import nn, optim
from torch.utils.data import DataLoader
from tqdm import tqdm


source_dir = '/Users/schmi/OneDrive/Área de Trabalho/images/images'
train_dir = '/Users/schmi/OneDrive/Área de Trabalho/images/train'
validation_dir = '/Users/schmi/OneDrive/Área de Trabalho/images/validation'
model_save_path = 'C:/Users/schmi/OneDrive/Área de Trabalho/images/modelo/vgg16_model.pth'

classes = [
    'disposable_plastic_cutlery', 'plastic_cup_lids', 'plastic_detergent_bottles', 
    'plastic_food_containers', 'plastic_shopping_bags', 'plastic_soda_bottles', 
    'plastic_straws', 'plastic_trash_bags', 'plastic_water_bottles', 'styrofoam_cups', 
    'styrofoam_food_containers', 'cardboard_boxes', 'cardboard_packaging', 'magazines', 
    'newspaper', 'office_paper', 'paper_cups', 'glass_beverage_bottles', 
    'glass_cosmetic_containers', 'glass_food_jars', 'aerosol_cans', 'aluminum_food_cans', 
    'aluminum_soda_cans', 'steel_food_cans', 'coffee_grounds', 'eggshells', 
    'food_waste', 'tea_bags', 'clothing', 'shoes'
]

def copy_images(src, dest, subfolder):
    if not os.path.exists(dest):
        os.makedirs(dest)
    for class_name in classes:
        src_class_dir = os.path.join(src, class_name, subfolder)
        dest_class_dir = os.path.join(dest, class_name)
        if not os.path.exists(dest_class_dir):
            os.makedirs(dest_class_dir)
        for image_name in os.listdir(src_class_dir):
            src_image = os.path.join(src_class_dir, image_name)
            dest_image = os.path.join(dest_class_dir, image_name)
            shutil.copyfile(src_image, dest_image)

copy_images(source_dir, train_dir, 'default')
copy_images(source_dir, validation_dir, 'real_world')

print(f"CUDA disponível: {torch.cuda.is_available()}")
print(f"Número de GPUs disponíveis: {torch.cuda.device_count()}")
for i in range(torch.cuda.device_count()):
    print(f"GPU {i}: {torch.cuda.get_device_name(i)}, Capacidade: {torch.cuda.get_device_properties(i).total_memory // (1024 ** 3)} GB")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Dispositivo atual: {device}")

#%%% Section 2: Criar DataLoaders e Verificar os Dados Carregados
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

print("Loading datasets...")
train_dataset = datasets.ImageFolder(train_dir, transform=transform)
validation_dataset = datasets.ImageFolder(validation_dir, transform=transform)

print(f"Número de imagens de treinamento: {len(train_dataset)}")
print(f"Número de imagens de validação: {len(validation_dataset)}")

print("Creating data loaders...")
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)
validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False, num_workers=0)

print("Verificando os dados carregados...")
print("Verificando dados do DataLoader de treinamento...")
for i, (images, labels) in enumerate(tqdm(train_loader, desc="Train Loader", unit="batch")):
    if i == 0:
        print(f"Tamanho do lote de treinamento: {images.size()}")
        print(f"Labels: {labels}")
    if i >= 10:
        break  # Verifica apenas os primeiros 10 batches para não demorar muito

print("Verificando dados do DataLoader de validação...")
for i, (images, labels) in enumerate(tqdm(validation_loader, desc="Validation Loader", unit="batch")):
    if i == 0:
        print(f"Tamanho do lote de validação: {images.size()}")
        print(f"Labels: {labels}")
    if i >= 10:
        break  # Verifica apenas os primeiros 10 batches para não demorar muito

print("Data loaders verified.")

#%%% Section 3: Definir e Treinar o Modelo

model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)
for param in model.parameters():
    param.requires_grad = False

# Modificar a camada totalmente conectada para se ajustar ao nosso número de classes
num_features = model.classifier[6].in_features
model.classifier[6] = nn.Linear(num_features, len(classes))
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001)

def save_checkpoint(state, filename=model_save_path):
    torch.save(state, filename)

num_epochs = 300
print("Iniciando treinamento...")
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} - Training", unit="batch"):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)

    epoch_loss = running_loss / len(train_loader.dataset)
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}")

    # Validação
    model.eval()
    running_corrects = 0
    with torch.no_grad():
        for inputs, labels in tqdm(validation_loader, desc=f"Epoch {epoch+1}/{num_epochs} - Validation", unit="batch"):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            running_corrects += torch.sum(preds == labels.data)

    epoch_acc = running_corrects.double() / len(validation_loader.dataset)
    print(f"Epoch {epoch+1}/{num_epochs}, Accuracy: {epoch_acc:.4f}")

    # Salvar o modelo após cada época
    save_checkpoint({
        'epoch': epoch + 1,
        'state_dict': model.state_dict(),
        'optimizer': optimizer.state_dict(),
        'loss': epoch_loss,
        'accuracy': epoch_acc,
    })
print("Treinamento concluído.")


#%%% Sub-Section 7.1: Importar bibliotecas para métricas
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np


def plot_confusion_matrix(cm, classes, normalize=False, title='Matriz de Confusão', cmap=plt.cm.Blues):
    """
    Esta função imprime e plota a matriz de confusão.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Matriz de Confusão Normalizada")
    else:
        print('Matriz de Confusão Sem Normalização')

    plt.figure(figsize=(20, 16))
    sns.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd', cmap=cmap, 
                xticklabels=classes, yticklabels=classes)
    plt.title(title)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for inputs, labels in tqdm(validation_loader, desc="Avaliação do Modelo", unit="batch"):
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())


cm = confusion_matrix(all_labels, all_preds)
plot_confusion_matrix(cm, classes=classes, normalize=True, title='Matriz de Confusão Normalizada')


report = classification_report(all_labels, all_preds, target_names=classes)
print("Relatório de Classificação:")
print(report)


accuracy = accuracy_score(all_labels, all_preds)
print(f"Acurácia do Modelo: {accuracy:.4f}")

#%%% Sub-Section 7.2: Importar bibliotecas para métricas
def plot_confusion_matrix(cm, classes, normalize=False, title='Matriz de Confusão', cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Matriz de Confusão Normalizada")
    else:
        print('Matriz de Confusão Sem Normalização')

    plt.figure(figsize=(20, 16), dpi=100)  # Aumentar a figura para maior resolução
    sns.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd', cmap=cmap, 
                xticklabels=classes, yticklabels=classes)
    plt.title(title)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for inputs, labels in tqdm(validation_loader, desc="Avaliação do Modelo", unit="batch"):
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

cm = confusion_matrix(all_labels, all_preds)
plot_confusion_matrix(cm, classes)
print(classification_report(all_labels, all_preds, target_names=classes))

accuracy = accuracy_score(all_labels, all_preds)
print(f"Acurácia do Modelo: {accuracy:.4f}")
